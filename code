# risk_model.py

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import os

# Load dataset
data_path = 'data/project_data.csv'
if not os.path.exists(data_path):
    raise FileNotFoundError(f"Dataset not found at {data_path}")

df = pd.read_csv(data_path)

# Basic preprocessing
if 'risk_level' not in df.columns:
    raise ValueError("Dataset must contain a 'risk_level' target column.")

# Encode target variable
le = LabelEncoder()
df['risk_level'] = le.fit_transform(df['risk_level'])  # Low=0, Med=1, High=2

# Handle categorical features
df = pd.get_dummies(df)

# Split features and target
X = df.drop('risk_level', axis=1)
y = df['risk_level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluation
y_pred = model.predict(X_test)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Save model and label encoder
os.makedirs('model', exist_ok=True)
joblib.dump(model, 'model/risk_model.pkl')
joblib.dump(le, 'model/label_encoder.pkl')
joblib.dump(scaler, 'model/scaler.pkl')

print("Model saved to 'model/risk_model.pkl'")
